{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c14c6f-36cb-4c49-80f3-2f611a7a3b0e",
   "metadata": {},
   "source": [
    "### Program to upload data into Milvus\n",
    "End result is a Collection \"demo_collection\" with all the data vectorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11368387-c521-4dbe-8834-8cf0e709fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymilvus\n",
      "  Using cached pymilvus-2.4.5-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: setuptools>69 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (70.1.0)\n",
      "Collecting grpcio<=1.63.0,>=1.49.1 (from pymilvus)\n",
      "  Downloading grpcio-1.63.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (4.25.4)\n",
      "Collecting environs<=9.5.0 (from pymilvus)\n",
      "  Using cached environs-9.5.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ujson>=2.0.0 (from pymilvus)\n",
      "  Downloading ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting pandas>=1.2.4 (from pymilvus)\n",
      "  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting milvus-lite<2.5.0,>=2.4.0 (from pymilvus)\n",
      "  Using cached milvus_lite-2.4.9-py3-none-manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting marshmallow>=3.0.0 (from environs<=9.5.0->pymilvus)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-dotenv (from environs<=9.5.0->pymilvus)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: tqdm in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from milvus-lite<2.5.0,>=2.4.0->pymilvus) (4.66.5)\n",
      "Collecting numpy>=1.22.4 (from pandas>=1.2.4->pymilvus)\n",
      "  Downloading numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2.4->pymilvus)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2.4->pymilvus)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Using cached pymilvus-2.4.5-py3-none-any.whl (197 kB)\n",
      "Using cached environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
      "Downloading grpcio-1.63.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached milvus_lite-2.4.9-py3-none-manylinux2014_x86_64.whl (49.4 MB)\n",
      "Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: pytz, ujson, tzdata, python-dotenv, numpy, milvus-lite, marshmallow, grpcio, pandas, environs, pymilvus\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.65.5\n",
      "    Uninstalling grpcio-1.65.5:\n",
      "      Successfully uninstalled grpcio-1.65.5\n",
      "Successfully installed environs-9.5.0 grpcio-1.63.0 marshmallow-3.22.0 milvus-lite-2.4.9 numpy-2.0.1 pandas-2.2.2 pymilvus-2.4.5 python-dotenv-1.0.1 pytz-2024.1 tzdata-2024.1 ujson-5.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pymilvus[model] in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (2.4.5)\n",
      "Requirement already satisfied: setuptools>69 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (70.1.0)\n",
      "Requirement already satisfied: grpcio<=1.63.0,>=1.49.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (1.63.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (4.25.4)\n",
      "Requirement already satisfied: environs<=9.5.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (2.2.2)\n",
      "Requirement already satisfied: milvus-lite<2.5.0,>=2.4.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus[model]) (2.4.9)\n",
      "Collecting milvus-model>=0.1.0 (from pymilvus[model])\n",
      "  Using cached milvus_model-0.2.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus[model]) (3.22.0)\n",
      "Requirement already satisfied: python-dotenv in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus[model]) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from milvus-lite<2.5.0,>=2.4.0->pymilvus[model]) (4.66.5)\n",
      "Collecting transformers>=4.36.0 (from milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting onnxruntime (from milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading onnxruntime-1.19.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting scipy>=1.10.0 (from milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from milvus-model>=0.1.0->pymilvus[model]) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus[model]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus[model]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus[model]) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus[model]) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[model]) (1.16.0)\n",
      "Collecting filelock (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading regex-2024.7.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading safetensors-0.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting coloredlogs (from onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting sympy (from onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (4.12.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.7.4)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached milvus_model-0.2.4-py3-none-any.whl (42 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached transformers-4.44.1-py3-none-any.whl (9.5 MB)\n",
      "Downloading onnxruntime-1.19.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.9/775.9 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.3/436.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, flatbuffers, sympy, scipy, safetensors, regex, humanfriendly, fsspec, filelock, huggingface-hub, coloredlogs, tokenizers, onnxruntime, transformers, milvus-model\n",
      "Successfully installed coloredlogs-15.0.1 filelock-3.15.4 flatbuffers-24.3.25 fsspec-2024.6.1 huggingface-hub-0.24.6 humanfriendly-10.0 milvus-model-0.2.4 mpmath-1.3.0 onnxruntime-1.19.0 regex-2024.7.24 safetensors-0.4.4 scipy-1.13.1 sympy-1.13.2 tokenizers-0.19.1 transformers-4.44.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pymilvus in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (2.4.5)\n",
      "Requirement already satisfied: transformers in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (4.44.1)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: setuptools>69 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (70.1.0)\n",
      "Requirement already satisfied: grpcio<=1.63.0,>=1.49.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (1.63.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (4.25.4)\n",
      "Requirement already satisfied: environs<=9.5.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (2.2.2)\n",
      "Requirement already satisfied: milvus-lite<2.5.0,>=2.4.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pymilvus) (2.4.9)\n",
      "Requirement already satisfied: filelock in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from transformers) (4.66.5)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from torch) (1.13.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Downloading triton-3.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus) (3.22.0)\n",
      "Requirement already satisfied: python-dotenv in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus) (1.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "Downloading torch-2.4.0-cp39-cp39-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-3.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: xxhash, triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, aiosignal, nvidia-cusolver-cu12, aiohttp, torch, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.21.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pyarrow-17.0.0 torch-2.4.0 triton-3.0.0 xxhash-3.5.0 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting clean-text\n",
      "  Using cached clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
      "  Using cached emoji-1.7.0.tar.gz (175 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy<7.0,>=6.0 (from clean-text)\n",
      "  Using cached ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/srini/AI-ML/testenv/lib/python3.9/site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
      "Using cached clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
      "Using cached ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171032 sha256=d7c9954333423715ae9db1993c4d331ec8abceb7c06df0e48127bf74d0100ea7\n",
      "  Stored in directory: /home/srini/.cache/pip/wheels/fa/7a/e9/22dd0515e1bad255e51663ee513a2fa839c95934c5fc301090\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, ftfy, clean-text\n",
      "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Program to upload data into Milvus\n",
    "!pip install -U pymilvus\n",
    "!pip install \"pymilvus[model]\"\n",
    "!pip install --upgrade pymilvus transformers datasets torch\n",
    "!pip install openpyxl\n",
    "!pip install clean-text\n",
    "# From\n",
    "# https://milvus.io/docs/integrate_with_hugging-face.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5637e59b-ee9e-47f8-ba07-1963d3aee37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mivus\n",
    "from pymilvus import MilvusClient, model,connections, db\n",
    "\n",
    "# Huggingface\n",
    "from datasets import Dataset, load_dataset # For loading\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import pandas as pd\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec59949-7e26-4004-bc0e-7e28d43d74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "milHost=\"192.168.1.44\"\n",
    "milURI='http://192.168.1.44:19530'\n",
    "milDBname=\"milvus_demo\"\n",
    "milCollection=\"demo_collection\"\n",
    "modelDimension= 384 # 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "170f4df1-2586-4b34-ad44-02d55b9891b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(io=\"/home/srini/AI-ML/CiscoTaskTracker.xlsx\", sheet_name=\"Gemini-test\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "416d7da5-0d17-4b41-80f4-e0477603ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 215 entries, 0 to 229\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Issue                 215 non-null    object\n",
      " 1   Incident Description  215 non-null    object\n",
      " 2   Responses             215 non-null    object\n",
      " 3   Context               215 non-null    object\n",
      " 4   Unnamed: 4            215 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 10.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue</th>\n",
       "      <th>Incident Description</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Context</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User want to know is it possible to configure ...</td>\n",
       "      <td>Hi Team,\\nINC9078040\\nissue: User want to know...</td>\n",
       "      <td>1)Opsmx replied as:-where in spinnaker it is a...</td>\n",
       "      <td>For dev pipelines user can add themselves in p...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spinnaker 4 Kubeconfig update 15 mins (Token e...</td>\n",
       "      <td>Hi Opsmx ,\\nMay i know if any testing is going...</td>\n",
       "      <td>Opsmx asked user to try once again.</td>\n",
       "      <td>monitor for 15 mins aftre token update the job...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Error loading config file</td>\n",
       "      <td>Hi Yeshashwini / OpsMx,\\n\\nDeployment are fail...</td>\n",
       "      <td>1)Opsmx suggested as need to check the Logs fo...</td>\n",
       "      <td>monitor for 15 mins aftre token update the job...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDeployment failed due to error with Anypoint...</td>\n",
       "      <td>Hi Yeshashwini/ OpsMx\\n\\nINC9097548\\nIssue: sp...</td>\n",
       "      <td>Opsmx suggested user need to check with anypo...</td>\n",
       "      <td>Need to check with anypoint platform team.</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exception in Dev env. related to GitHub ,\\nRep...</td>\n",
       "      <td>Hi Yeshashwini/ Opsmx\\nSpinnaker deployment is...</td>\n",
       "      <td>Opsmx suggested as:- \\n1)Can you check with gi...</td>\n",
       "      <td>As the error clearly shows 404 status for gith...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Issue  \\\n",
       "0  User want to know is it possible to configure ...   \n",
       "1  Spinnaker 4 Kubeconfig update 15 mins (Token e...   \n",
       "2                          Error loading config file   \n",
       "3  \\nDeployment failed due to error with Anypoint...   \n",
       "4  Exception in Dev env. related to GitHub ,\\nRep...   \n",
       "\n",
       "                                Incident Description  \\\n",
       "0  Hi Team,\\nINC9078040\\nissue: User want to know...   \n",
       "1  Hi Opsmx ,\\nMay i know if any testing is going...   \n",
       "2  Hi Yeshashwini / OpsMx,\\n\\nDeployment are fail...   \n",
       "3  Hi Yeshashwini/ OpsMx\\n\\nINC9097548\\nIssue: sp...   \n",
       "4  Hi Yeshashwini/ Opsmx\\nSpinnaker deployment is...   \n",
       "\n",
       "                                           Responses  \\\n",
       "0  1)Opsmx replied as:-where in spinnaker it is a...   \n",
       "1                Opsmx asked user to try once again.   \n",
       "2  1)Opsmx suggested as need to check the Logs fo...   \n",
       "3   Opsmx suggested user need to check with anypo...   \n",
       "4  Opsmx suggested as:- \\n1)Can you check with gi...   \n",
       "\n",
       "                                             Context Unnamed: 4  \n",
       "0  For dev pipelines user can add themselves in p...         NA  \n",
       "1  monitor for 15 mins aftre token update the job...         NA  \n",
       "2  monitor for 15 mins aftre token update the job...         NA  \n",
       "3         Need to check with anypoint platform team.         NA  \n",
       "4  As the error clearly shows 404 status for gith...         NA  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns, cleanup, fillNA, else tokanization fails\n",
    "df.dropna(axis=0,how=\"all\",inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "#df = df.drop(df.columns[4], axis=1)\n",
    "df = df.fillna(\"NA\")\n",
    "df.shape\n",
    "df.info()\n",
    "df.isna().sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f173b22-5d95-4ed2-89d7-dfc8f6bbff1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue</th>\n",
       "      <th>Incident Description</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Context</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user want to know is it possible to configure ...</td>\n",
       "      <td>hi team, inc9078040 issue: user want to know i...</td>\n",
       "      <td>1)opsmx replied as:-where in spinnaker it is a...</td>\n",
       "      <td>for dev pipelines user can add themselves in p...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spinnaker 4 kubeconfig update 15 mins (token e...</td>\n",
       "      <td>hi opsmx , may i know if any testing is going ...</td>\n",
       "      <td>opsmx asked user to try once again.</td>\n",
       "      <td>monitor for 15 mins aftre token update the job...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>error loading config file</td>\n",
       "      <td>hi yeshashwini / opsmx, deployment are failing...</td>\n",
       "      <td>1)opsmx suggested as need to check the logs fo...</td>\n",
       "      <td>monitor for 15 mins aftre token update the job...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deployment failed due to error with anypoint p...</td>\n",
       "      <td>hi yeshashwini/ opsmx inc9097548 issue: spinna...</td>\n",
       "      <td>opsmx suggested user need to check with anypoi...</td>\n",
       "      <td>need to check with anypoint platform team.</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exception in dev env. related to github , repe...</td>\n",
       "      <td>hi yeshashwini/ opsmx spinnaker deployment is ...</td>\n",
       "      <td>opsmx suggested as:- 1)can you check with gith...</td>\n",
       "      <td>as the error clearly shows 404 status for gith...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Issue  \\\n",
       "0  user want to know is it possible to configure ...   \n",
       "1  spinnaker 4 kubeconfig update 15 mins (token e...   \n",
       "2                          error loading config file   \n",
       "3  deployment failed due to error with anypoint p...   \n",
       "4  exception in dev env. related to github , repe...   \n",
       "\n",
       "                                Incident Description  \\\n",
       "0  hi team, inc9078040 issue: user want to know i...   \n",
       "1  hi opsmx , may i know if any testing is going ...   \n",
       "2  hi yeshashwini / opsmx, deployment are failing...   \n",
       "3  hi yeshashwini/ opsmx inc9097548 issue: spinna...   \n",
       "4  hi yeshashwini/ opsmx spinnaker deployment is ...   \n",
       "\n",
       "                                           Responses  \\\n",
       "0  1)opsmx replied as:-where in spinnaker it is a...   \n",
       "1                opsmx asked user to try once again.   \n",
       "2  1)opsmx suggested as need to check the logs fo...   \n",
       "3  opsmx suggested user need to check with anypoi...   \n",
       "4  opsmx suggested as:- 1)can you check with gith...   \n",
       "\n",
       "                                             Context Unnamed: 4  \n",
       "0  for dev pipelines user can add themselves in p...         na  \n",
       "1  monitor for 15 mins aftre token update the job...         na  \n",
       "2  monitor for 15 mins aftre token update the job...         na  \n",
       "3         need to check with anypoint platform team.         na  \n",
       "4  as the error clearly shows 404 status for gith...         na  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanEveryCell(text) :\n",
    "    return clean(text=text,\n",
    "            fix_unicode=True,\n",
    "            to_ascii=True,\n",
    "            lower=True,\n",
    "            no_line_breaks=True,\n",
    "            no_urls=True,\n",
    "            no_emails=True,\n",
    "            no_phone_numbers=False,\n",
    "            no_numbers=False,\n",
    "            no_digits=False,\n",
    "            no_currency_symbols=False,\n",
    "            no_punct=False,\n",
    "            replace_with_punct=\"\",\n",
    "            replace_with_url=\"This is a URL\",\n",
    "            replace_with_email=\"Email\",\n",
    "            replace_with_phone_number=\"\",\n",
    "            replace_with_number=\"123\",\n",
    "            replace_with_digit=\"0\",\n",
    "            replace_with_currency_symbol=\"$\",\n",
    "            lang=\"en\"\n",
    "            )\n",
    "\n",
    "df = df.applymap(cleanEveryCell)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e76860e-01d9-4429-8990-fdfb1ee7431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "768aa76b-e587-4f74-b1a5-6b9cc48781e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Issue', 'Incident Description', 'Responses', 'Context', 'Unnamed: 4', '__index_level_0__'],\n",
      "    num_rows: 215\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8912895-6436-47d3-9fc3-77aef2979eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srini/AI-ML/srinitest/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This is model being used for RAG, not for inference\n",
    "MODEL =  \"sentence-transformers/all-MiniLM-L6-v2\"  # Name of model from HuggingFace Models\n",
    "INFERENCE_BATCH_SIZE = 64  # Batch size of model inference, may be used for uploading the docs into Milvus?\n",
    "\n",
    "# Load tokenizer & model from HuggingFace Hub\n",
    "ragTokenizer = AutoTokenizer.from_pretrained(MODEL) #This will be used to tokenize the inputs and uploading into Milvus\n",
    "ragModel = AutoModel.from_pretrained(MODEL) # This should be used for finding relavent docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fea024d7-e5a8-4d6b-9865-ae5d6edfac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to understand this, I am tokenizing only the incident description\n",
    "def encode_text(batch):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = ragTokenizer(\n",
    "        batch[\"Incident Description\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = ragModel(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    token_embeddings = model_output[0]\n",
    "    attention_mask = encoded_input[\"attention_mask\"]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sentence_embeddings = torch.sum(\n",
    "        token_embeddings * input_mask_expanded, 1\n",
    "    ) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    batch[\"description_embedding\"] = torch.nn.functional.normalize(\n",
    "        sentence_embeddings, p=2, dim=1\n",
    "    )\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1e13f13-0b25-4b2c-b314-56be35bb6d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ac1d686686406f812cfb7d0752a419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode Data\n",
    "data = data.map(encode_text, batched=True, batch_size=INFERENCE_BATCH_SIZE)\n",
    "data_list = data.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de38e44f-5495-4510-940d-a79e66b14851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DB only once\n",
    "#conn = connections.connect(host=\"192.168.1.44\", port=19530)\n",
    "#database = db.create_database(\"milvus_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc04f3ec-5ae9-4c33-8e66-acc1bf2e0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = MilvusClient(uri=milURI,db_name=milDBname, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4bc9139-88bd-41c2-897a-fdc5f46fad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client = MilvusClient(milURI)\n",
    "if milvus_client.has_collection(collection_name=milCollection):\n",
    "    milvus_client.drop_collection(collection_name=milCollection)\n",
    "milvus_client.create_collection(\n",
    "    collection_name=milCollection,\n",
    "    dimension=modelDimension,\n",
    "    auto_id=True,  # Enable auto id\n",
    "    enable_dynamic_field=True,  # Enable dynamic fields\n",
    "    vector_field_name=\"description_embedding\",  # Map vector field name and embedding column in dataset\n",
    "    consistency_level=\"Strong\",  # To enable search with latest data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b15ba2d3-7f37-4801-b2a4-c0061e1d7166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_collection']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List Collections\n",
    "#client.list_collections()\n",
    "milvus_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "673c6845-af93-4157-87ab-6f4fc2579442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 215, 'ids': [451987299360597900, 451987299360597901, 451987299360597902, 451987299360597903, 451987299360597904, 451987299360597905, 451987299360597906, 451987299360597907, 451987299360597908, 451987299360597909, 451987299360597910, 451987299360597911, 451987299360597912, 451987299360597913, 451987299360597914, 451987299360597915, 451987299360597916, 451987299360597917, 451987299360597918, 451987299360597919, 451987299360597920, 451987299360597921, 451987299360597922, 451987299360597923, 451987299360597924, 451987299360597925, 451987299360597926, 451987299360597927, 451987299360597928, 451987299360597929, 451987299360597930, 451987299360597931, 451987299360597932, 451987299360597933, 451987299360597934, 451987299360597935, 451987299360597936, 451987299360597937, 451987299360597938, 451987299360597939, 451987299360597940, 451987299360597941, 451987299360597942, 451987299360597943, 451987299360597944, 451987299360597945, 451987299360597946, 451987299360597947, 451987299360597948, 451987299360597949, 451987299360597950, 451987299360597951, 451987299360597952, 451987299360597953, 451987299360597954, 451987299360597955, 451987299360597956, 451987299360597957, 451987299360597958, 451987299360597959, 451987299360597960, 451987299360597961, 451987299360597962, 451987299360597963, 451987299360597964, 451987299360597965, 451987299360597966, 451987299360597967, 451987299360597968, 451987299360597969, 451987299360597970, 451987299360597971, 451987299360597972, 451987299360597973, 451987299360597974, 451987299360597975, 451987299360597976, 451987299360597977, 451987299360597978, 451987299360597979, 451987299360597980, 451987299360597981, 451987299360597982, 451987299360597983, 451987299360597984, 451987299360597985, 451987299360597986, 451987299360597987, 451987299360597988, 451987299360597989, 451987299360597990, 451987299360597991, 451987299360597992, 451987299360597993, 451987299360597994, 451987299360597995, 451987299360597996, 451987299360597997, 451987299360597998, 451987299360597999, 451987299360598000, 451987299360598001, 451987299360598002, 451987299360598003, 451987299360598004, 451987299360598005, 451987299360598006, 451987299360598007, 451987299360598008, 451987299360598009, 451987299360598010, 451987299360598011, 451987299360598012, 451987299360598013, 451987299360598014, 451987299360598015, 451987299360598016, 451987299360598017, 451987299360598018, 451987299360598019, 451987299360598020, 451987299360598021, 451987299360598022, 451987299360598023, 451987299360598024, 451987299360598025, 451987299360598026, 451987299360598027, 451987299360598028, 451987299360598029, 451987299360598030, 451987299360598031, 451987299360598032, 451987299360598033, 451987299360598034, 451987299360598035, 451987299360598036, 451987299360598037, 451987299360598038, 451987299360598039, 451987299360598040, 451987299360598041, 451987299360598042, 451987299360598043, 451987299360598044, 451987299360598045, 451987299360598046, 451987299360598047, 451987299360598048, 451987299360598049, 451987299360598050, 451987299360598051, 451987299360598052, 451987299360598053, 451987299360598054, 451987299360598055, 451987299360598056, 451987299360598057, 451987299360598058, 451987299360598059, 451987299360598060, 451987299360598061, 451987299360598062, 451987299360598063, 451987299360598064, 451987299360598065, 451987299360598066, 451987299360598067, 451987299360598068, 451987299360598069, 451987299360598070, 451987299360598071, 451987299360598072, 451987299360598073, 451987299360598074, 451987299360598075, 451987299360598076, 451987299360598077, 451987299360598078, 451987299360598079, 451987299360598080, 451987299360598081, 451987299360598082, 451987299360598083, 451987299360598084, 451987299360598085, 451987299360598086, 451987299360598087, 451987299360598088, 451987299360598089, 451987299360598090, 451987299360598091, 451987299360598092, 451987299360598093, 451987299360598094, 451987299360598095, 451987299360598096, 451987299360598097, 451987299360598098, 451987299360598099, 451987299360598100, 451987299360598101, 451987299360598102, 451987299360598103, 451987299360598104, 451987299360598105, 451987299360598106, 451987299360598107, 451987299360598108, 451987299360598109, 451987299360598110, 451987299360598111, 451987299360598112, 451987299360598113, 451987299360598114], 'cost': 0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload Data into Milvus\n",
    "milvus_client.insert(collection_name=milCollection, data=data_list)\n",
    "\n",
    "# Default embedding model\n",
    "#embedding_fn = model.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c039571e-2a8f-4d92-9889-afd9b52a24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {\n",
    "    \"Incident Description\": [\n",
    "        \"deployments are failing\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate question embeddings\n",
    "question_embeddings = [v.tolist() for v in encode_text(questions)[\"description_embedding\"]]\n",
    "\n",
    "#print(question_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e0f9a97-7031-4264-ab78-044be550058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we search for our Incident description in Milvus\n",
    "search_results = milvus_client.search(\n",
    "    collection_name=milCollection,\n",
    "    data=question_embeddings,\n",
    "    limit=3,  # How many search results to output\n",
    "    output_fields=[\"Responses\", \"Context\"],  # Include these fields in search results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47c5b799-e785-4686-b84e-83c4eb5083ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident Description: deployments are failing\n",
      "{'answer': '1) cisco team has asked the user to re-try and deployment was successful', 'score': 0.7182451486587524}\n",
      "{'answer': 'opsmx suggested as:- 1)cae-np-rtp2-919f5a this account is not present in clouddriver.yml can you check with user to add this account first and then re-execute the pipeline browse code tools: spinnaker tools / dynamic-clouddriver-accounts - gitscm (cisco.com)', 'score': 0.6687703728675842}\n",
      "{'answer': 'opsmx suggested as because when pipeline ran(failed one) at time kube config was not update and it was not able to deploy every 15 min, as cae culster token being renewed', 'score': 0.6241561770439148}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out results\n",
    "for q, res in zip(questions[\"Incident Description\"], search_results):\n",
    "    print(\"Incident Description:\", q)\n",
    "    for r in res:\n",
    "        print(\n",
    "            {\n",
    "                \"answer\": r[\"entity\"][\"Responses\"],\n",
    "                \"score\": r[\"distance\"],\n",
    "            }\n",
    "        )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf516a5-4a5f-481e-8136-0e2302cc444b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1730a-9bfb-4316-9e30-0ba5d30346e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4efd9-7e03-4a2c-a8f5-9fc1f3c262ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
